# Explaining Black Box with visual exploration of Latent Space
探索了Autoencoder的latent space and real space 之间的关系

论文中使用了SHAP来解释一个深度学习模型输入对输出之间的关系，输入的重要性
SHAP是一个非常有用的解释模型
https://proceedings.neurips.cc/paper/2017/file/8a20a8621978632d76c43dfd28b67767-Paper.pdf

这个方法只做了泰坦尼克号数据集的数据可视化，针对的是离散的数据集，可视化了
特征对最终潜空间位置的贡献。


引用格式
Bodria F, Rinzivillo S, Fadda D, et al. Explaining Black Box with visual exploration of Latent Space[J]. 2022.

@article{bodria2022explaining,
  title={Explaining Black Box with visual exploration of Latent Space},
  author={Bodria, Francesco and Rinzivillo, Salvatore and Fadda, Daniele and Guidotti, Riccardo and Giannotti, Fosca and Pedreschi, Dino},
  year={2022},
  publisher={The Eurographics Association}
}